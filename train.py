import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torchvision import datasets
from timm import create_model
from torch.amp import autocast, GradScaler

# ‚úÖ Configuration
DATA_DIR = r'D:\Face Recognition-Dip Project\train'
CHECKPOINT_DIR = r'D:\Face Recognition-Dip Project\checkpoints'
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

BATCH_SIZE = 32
NUM_EPOCHS = 10
LEARNING_RATE = 1e-4
IMAGE_SIZE = 224

# ‚úÖ Device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"‚úÖ Using Device: {device}")

# ‚úÖ Transform
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# ‚úÖ Load Dataset
try:
    dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)
    class_names = dataset.classes
    num_classes = len(class_names)
    print(f"‚úÖ Dataset Loaded: {len(dataset)} images | {num_classes} classes")
except Exception as e:
    print(f"‚ùå Dataset Load Error: {e}")
    sys.exit()

# ‚úÖ Train Function
def train():
    # ‚úÖ DataLoader
    train_loader = DataLoader(
        dataset, batch_size=BATCH_SIZE, shuffle=True,
        num_workers=4, pin_memory=True if device.type == 'cuda' else False
    )

    # ‚úÖ Model Setup
    try:
        model = create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes).to(device)
        print("‚úÖ Model Loaded Successfully!")
    except Exception as e:
        print(f"‚ùå Model Load Error: {e}")
        return

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)
    scaler = GradScaler(enabled=(device.type == 'cuda'))

    for epoch in range(NUM_EPOCHS):
        print(f"\nüöÄ Starting Epoch {epoch + 1}/{NUM_EPOCHS}")
        model.train()
        total_loss, correct, total = 0, 0, 0

        for batch_idx, (images, labels) in enumerate(train_loader, 1):
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            optimizer.zero_grad()

            with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):
                outputs = model(images)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            total_loss += loss.item()
            preds = outputs.argmax(dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # ‚úÖ Progress Log (Optional)
            sys.stdout.write(
                f"\rüîÑ Batch {batch_idx}/{len(train_loader)} - "
                f"Loss: {loss.item():.4f} | Accuracy: {(correct / total * 100):.2f}%"
            )
            sys.stdout.flush()

        avg_loss = total_loss / len(train_loader)
        epoch_acc = correct / total * 100
        print(f"\n‚úÖ Epoch {epoch + 1} Complete - Loss: {avg_loss:.4f} | Accuracy: {epoch_acc:.2f}%")

        # üíæ Save checkpoint every 2 epochs
        if (epoch + 1) % 2 == 0:
            checkpoint_path = os.path.join(CHECKPOINT_DIR, f"vit_vggface2_epoch{epoch + 1}.pth")
            torch.save(model.state_dict(), checkpoint_path)
            print(f"üíæ Checkpoint saved: {checkpoint_path}")

    # üíæ Save final model
    final_path = os.path.join(CHECKPOINT_DIR, 'vit_vggface2_final.pth')
    torch.save(model.state_dict(), final_path)
    print("‚úÖ Training Complete! Final model saved.")

# ‚úÖ Windows-safe start
if __name__ == '__main__':
    train()
